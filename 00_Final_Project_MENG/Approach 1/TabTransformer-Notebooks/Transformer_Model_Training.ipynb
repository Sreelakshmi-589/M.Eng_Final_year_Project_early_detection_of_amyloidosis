{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Function to set all random seeds for reproducibility\n",
    "def set_all_seeds(seed):\n",
    "    \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    # Setting seed for built-in random module\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Setting seed for numpy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Setting seed for PyTorch on CPU\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # setting seeds for CUDA and enforce deterministic behavior\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)           # For multi-GPU setups\n",
    "        torch.backends.cudnn.deterministic = True  # Ensuring deterministic convolution algorithms\n",
    "        torch.backends.cudnn.benchmark = False     # Disabling auto-tuner to ensure reproducibility\n",
    "\n",
    "# Setting a fixed random seed\n",
    "MY_RANDOM_SEED = 42 \n",
    "set_all_seeds(MY_RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA-enabled GPU is available\n",
    "print(torch.cuda.is_available())  \n",
    "\n",
    "# Print the number of GPUs detected by PyTorch\n",
    "print(torch.cuda.device_count())  \n",
    "\n",
    "# printing the name of the available GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))  \n",
    "    # Index 0 refers to the first GPU\n",
    "    # This helps confirm which GPU the notebook is using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.7.1+cu118\n",
      "pytorch-lightning: 2.4.0\n",
      "pytorch-tabular: 1.1.1\n",
      "tensorboard: 2.19.0\n",
      "protobuf: 3.20.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_tabular\n",
    "import tensorboard\n",
    "import google.protobuf\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"pytorch-lightning:\", pl.__version__)\n",
    "print(\"pytorch-tabular:\", pytorch_tabular.__version__)\n",
    "print(\"tensorboard:\", tensorboard.__version__)\n",
    "print(\"protobuf:\", google.protobuf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 24060,
     "status": "ok",
     "timestamp": 1754062740838,
     "user": {
      "displayName": "Sreelakshmi K",
      "userId": "11864479199834767492"
     },
     "user_tz": -60
    },
    "id": "PzX83HVPH3Ak"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.tab_transformer.config import TabTransformerConfig\n",
    "from pytorch_tabular import TabularModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1754062744733,
     "user": {
      "displayName": "Sreelakshmi K",
      "userId": "11864479199834767492"
     },
     "user_tz": -60
    },
    "id": "BlOu5E2k8LNu",
    "outputId": "f917a641-42a1-485a-b907-91b2bc3b77ba"
   },
   "outputs": [],
   "source": [
    "# Loading Train dataset \n",
    "df = pd.read_csv(\"C:/Users/Sreelakshmi/00_Final_Project_MENG/Approach 1/Dataset_1/train_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shape: (1499, 1873)\n"
     ]
    }
   ],
   "source": [
    "# Total number of columns and rows in the training DataFrame\n",
    "print(f\"Train DataFrame shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdominal_and_pelvic_pain</th>\n",
       "      <th>abdominal_aortic_aneurysm__without_rupture</th>\n",
       "      <th>abdominal_distension__gaseous_</th>\n",
       "      <th>abn_findings_on_dx_imaging_of_abd_regions__inc_retroperiton</th>\n",
       "      <th>abnormal_and_inconclusive_findings_on_dx_imaging_of_breast</th>\n",
       "      <th>abnormal_blood_pressure_reading__without_diagnosis</th>\n",
       "      <th>abnormal_coagulation_profile</th>\n",
       "      <th>abnormal_electrocardiogram__ecg___ekg_</th>\n",
       "      <th>abnormal_finding_of_blood_chemistry__unspecified</th>\n",
       "      <th>abnormal_findings_on_diagnostic_imaging_and_in_function_studies__without_diagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>vomiting__unspecified</th>\n",
       "      <th>vomiting_without_nausea</th>\n",
       "      <th>weakness</th>\n",
       "      <th>wheezing</th>\n",
       "      <th>white_matter_disease__unspecified</th>\n",
       "      <th>wtrcraft_fall_nos_crew</th>\n",
       "      <th>xerosis_cutis</th>\n",
       "      <th>zoster__herpes_zoster_</th>\n",
       "      <th>zoster_without_complications</th>\n",
       "      <th>__target__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1873 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abdominal_and_pelvic_pain  abdominal_aortic_aneurysm__without_rupture  \\\n",
       "0                          0                                           0   \n",
       "1                          1                                           0   \n",
       "2                          1                                           0   \n",
       "3                          1                                           0   \n",
       "4                          1                                           0   \n",
       "\n",
       "   abdominal_distension__gaseous_  \\\n",
       "0                               0   \n",
       "1                               0   \n",
       "2                               0   \n",
       "3                               0   \n",
       "4                               1   \n",
       "\n",
       "   abn_findings_on_dx_imaging_of_abd_regions__inc_retroperiton  \\\n",
       "0                                                  0             \n",
       "1                                                  0             \n",
       "2                                                  0             \n",
       "3                                                  0             \n",
       "4                                                  0             \n",
       "\n",
       "   abnormal_and_inconclusive_findings_on_dx_imaging_of_breast  \\\n",
       "0                                                  0            \n",
       "1                                                  0            \n",
       "2                                                  0            \n",
       "3                                                  0            \n",
       "4                                                  0            \n",
       "\n",
       "   abnormal_blood_pressure_reading__without_diagnosis  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "\n",
       "   abnormal_coagulation_profile  abnormal_electrocardiogram__ecg___ekg_  \\\n",
       "0                             0                                       0   \n",
       "1                             0                                       0   \n",
       "2                             1                                       1   \n",
       "3                             0                                       0   \n",
       "4                             0                                       1   \n",
       "\n",
       "   abnormal_finding_of_blood_chemistry__unspecified  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "\n",
       "   abnormal_findings_on_diagnostic_imaging_and_in_function_studies__without_diagnosis  \\\n",
       "0                                                  0                                    \n",
       "1                                                  0                                    \n",
       "2                                                  1                                    \n",
       "3                                                  0                                    \n",
       "4                                                  1                                    \n",
       "\n",
       "   ...  vomiting__unspecified  vomiting_without_nausea  weakness  wheezing  \\\n",
       "0  ...                      0                        0         0         0   \n",
       "1  ...                      0                        0         1         0   \n",
       "2  ...                      0                        0         1         0   \n",
       "3  ...                      0                        0         0         0   \n",
       "4  ...                      0                        0         1         0   \n",
       "\n",
       "   white_matter_disease__unspecified  wtrcraft_fall_nos_crew  xerosis_cutis  \\\n",
       "0                                  0                       0              0   \n",
       "1                                  0                       0              0   \n",
       "2                                  0                       0              0   \n",
       "3                                  0                       0              0   \n",
       "4                                  0                       0              0   \n",
       "\n",
       "   zoster__herpes_zoster_  zoster_without_complications  __target__  \n",
       "0                       0                             0           0  \n",
       "1                       1                             1           0  \n",
       "2                       0                             0           0  \n",
       "3                       0                             0           0  \n",
       "4                       0                             0           1  \n",
       "\n",
       "[5 rows x 1873 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['abdominal_and_pelvic_pain', 'abdominal_aortic_aneurysm__without_rupture', 'abdominal_distension__gaseous_', 'abn_findings_on_dx_imaging_of_abd_regions__inc_retroperiton', 'abnormal_and_inconclusive_findings_on_dx_imaging_of_breast', 'abnormal_blood_pressure_reading__without_diagnosis', 'abnormal_coagulation_profile', 'abnormal_electrocardiogram__ecg___ekg_', 'abnormal_finding_of_blood_chemistry__unspecified', 'abnormal_findings_on_diagnostic_imaging_and_in_function_studies__without_diagnosis'] ...\n",
      "Target: __target__\n"
     ]
    }
   ],
   "source": [
    "target_col = '__target__'\n",
    "features = df.drop(columns=[target_col]).columns.tolist()\n",
    "\n",
    "print(f\"Features: {features[:10]} ...\")\n",
    "print(f\"Target: {target_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Sreelakshmi/00_Final_Project_MENG/Approach 1/TabTransformer/tabTransformer_scaler.sav']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'C:/Users/Sreelakshmi/00_Final_Project_MENG/Approach 1/TabTransformer/tabTransformer_scaler.sav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing scaled DataFrame\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=features)  # Convert scaled array back to DataFrame\n",
    "train_df_scaled = X_scaled_df.copy()\n",
    "train_df_scaled[target_col] = df[target_col]           # Add target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the data configuration\n",
    "data_config = DataConfig(\n",
    "    target=[target_col], # This tells PyTorch-Tabular which column to predict\n",
    "    continuous_cols=features, # List of feature column names that are continuous/numeric\n",
    "    # categorical_cols=[]  # Add if you have categorical features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "trainer_config = TrainerConfig(\n",
    "    max_epochs=50,                  # Maximum number of training epochs\n",
    "    batch_size=512,                 # Number of samples per batch\n",
    "    progress_bar=\"none\",            # Disable progress bar \n",
    "    early_stopping=\"valid_loss\",    # Stop training if validation loss stops improving\n",
    "    checkpoints=\"valid_loss\",       # Save the best model based on validation loss\n",
    "    \n",
    ")\n",
    "\n",
    "# Optimizer configuration\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "# Default optimizer is usually Adam. You can customize learning rate, weight decay, etc.\n",
    "# Example: OptimizerConfig(optimizer=\"Adam\", lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "# Model configuration (TabTransformer)\n",
    "\n",
    "model_config = TabTransformerConfig(\n",
    "    task=\"classification\",             # \"classification\" or \"regression\"\n",
    "    learning_rate=1e-3,                # Learning rate for optimizer\n",
    "    input_embed_dim=64,                # Dimension of embeddings for each feature\n",
    "    num_heads=8,                       # Number of attention heads in transformer\n",
    "    num_attn_blocks=6,                 # Number of transformer blocks/layers\n",
    "    embedding_dropout=0.1,             # Dropout for embeddings (prevents overfitting)\n",
    "    batch_norm_continuous_input=True,  # Apply batch normalization to continuous features\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:06:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">863</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m17\u001b[0m \u001b[1;92m14:06:34\u001b[0m,\u001b[1;36m863\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize TabularModel\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,           # Specifies target, continuous, and categorical columns\n",
    "    model_config=model_config,         # Specifies TabTransformer architecture and hyperparameters\n",
    "    optimizer_config=optimizer_config, # Optimizer settings (learning rate, type, etc.)\n",
    "    trainer_config=trainer_config,     # Training behavior (epochs, batch size, early stopping)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:06:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">973</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m17\u001b[0m \u001b[1;92m14:06:39\u001b[0m,\u001b[1;36m973\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:06:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">006</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m17\u001b[0m \u001b[1;92m14:06:40\u001b[0m,\u001b[1;36m006\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:06:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">597</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabTransformerModel    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m17\u001b[0m \u001b[1;92m14:06:40\u001b[0m,\u001b[1;36m597\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabTransformerModel    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:06:41</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">131</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m17\u001b[0m \u001b[1;92m14:06:41\u001b[0m,\u001b[1;36m131\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:06:41</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">188</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m17\u001b[0m \u001b[1;92m14:06:41\u001b[0m,\u001b[1;36m188\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sreelakshmi\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Sreelakshmi\\00_Final_Project_MENG\\Approach 1\\TabTransformer-Notebooks\\saved_models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                   | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | _backbone        | TabTransformerBackbone | 1.1 M  | train\n",
      "1 | _embedding_layer | Embedding2dLayer       | 0      | train\n",
      "2 | _head            | LinearHead             | 3.7 K  | train\n",
      "3 | loss             | CrossEntropyLoss       | 0      | train\n",
      "--------------------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.363     Total estimated model params size (MB)\n",
      "120       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "C:\\Users\\Sreelakshmi\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Sreelakshmi\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Sreelakshmi\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:06:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">216</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m17\u001b[0m \u001b[1;92m14:06:46\u001b[0m,\u001b[1;36m216\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:06:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">221</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m17\u001b[0m \u001b[1;92m14:06:46\u001b[0m,\u001b[1;36m221\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'_SpecialForm' object has no attribute '__qualname__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 22\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# PyTorch-Tabular uses OmegaConf objects internally for configs.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# `torch.serialization.safe_globals` ensures that certain object types are treated as safe during serialization (e.g., when saving/loading checkpoints).\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39msafe_globals([\n\u001b[0;32m     11\u001b[0m     omegaconf\u001b[38;5;241m.\u001b[39mdictconfig\u001b[38;5;241m.\u001b[39mDictConfig,        \u001b[38;5;66;03m# OmegaConf dictionary config\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     omegaconf\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mContainerMetadata,       \u001b[38;5;66;03m# Metadata for OmegaConf objects\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mtabular_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Training DataFrame (scaled/processed)\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\pytorch_tabular\\tabular_model.py:806\u001b[0m, in \u001b[0;36mTabularModel.fit\u001b[1;34m(self, train, validation, loss, metrics, metrics_prob_inputs, optimizer, optimizer_params, train_sampler, target_transform, max_epochs, min_epochs, seed, callbacks, datamodule, cache_data, handle_oom)\u001b[0m\n\u001b[0;32m    792\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    793\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain data and datamodule is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Ignoring the train data and using the datamodule.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Set either one of them to None to avoid this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m         )\n\u001b[0;32m    797\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_model(\n\u001b[0;32m    798\u001b[0m     datamodule,\n\u001b[0;32m    799\u001b[0m     loss,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    803\u001b[0m     optimizer_params \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[0;32m    804\u001b[0m )\n\u001b[1;32m--> 806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_oom\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\pytorch_tabular\\tabular_model.py:691\u001b[0m, in \u001b[0;36mTabularModel.train\u001b[1;34m(self, model, datamodule, callbacks, max_epochs, min_epochs, handle_oom)\u001b[0m\n\u001b[0;32m    689\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mload_best:\n\u001b[1;32m--> 691\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\pytorch_tabular\\tabular_model.py:1534\u001b[0m, in \u001b[0;36mTabularModel.load_best_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m   1533\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1534\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\pytorch_tabular\\utils\\python_utils.py:85\u001b[0m, in \u001b[0;36mpl_load\u001b[1;34m(path_or_url, map_location)\u001b[0m\n\u001b[0;32m     83\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mopen(path_or_url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\torch\\serialization.py:1516\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m   1515\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1516\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1517\u001b[0m             opened_zipfile,\n\u001b[0;32m   1518\u001b[0m             map_location,\n\u001b[0;32m   1519\u001b[0m             _weights_only_unpickler,\n\u001b[0;32m   1520\u001b[0m             overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[0;32m   1521\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1522\u001b[0m         )\n\u001b[0;32m   1523\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\torch\\serialization.py:2114\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   2112\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[0;32m   2113\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 2114\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2115\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2117\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\torch\\_weights_only_unpickler.py:337\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_path \u001b[38;5;129;01min\u001b[39;00m _get_allowed_globals():\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(_get_allowed_globals()[full_path])\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m full_path \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_get_user_allowed_globals\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(_get_user_allowed_globals()[full_path])\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m full_path \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m    340\u001b[0m     [\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.nested._internal.nested_tensor.NestedTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m     ]\n\u001b[0;32m    345\u001b[0m ):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tabular_final_env\\lib\\site-packages\\torch\\_weights_only_unpickler.py:144\u001b[0m, in \u001b[0;36m_get_user_allowed_globals\u001b[1;34m()\u001b[0m\n\u001b[0;32m    142\u001b[0m         rc[name] \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         module, name \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[0;32m    145\u001b[0m         rc[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rc\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_SpecialForm' object has no attribute '__qualname__'"
     ]
    }
   ],
   "source": [
    "# Safe context for model.fit\n",
    "\n",
    "import torch\n",
    "import omegaconf\n",
    "import typing\n",
    "import collections\n",
    "\n",
    "# PyTorch-Tabular uses OmegaConf objects internally for configs.\n",
    "# `torch.serialization.safe_globals` ensures that certain object types are treated as safe during serialization (e.g., when saving/loading checkpoints).\n",
    "with torch.serialization.safe_globals([\n",
    "    omegaconf.dictconfig.DictConfig,        # OmegaConf dictionary config\n",
    "    omegaconf.base.ContainerMetadata,       # Metadata for OmegaConf objects\n",
    "    omegaconf.listconfig.ListConfig,        # OmegaConf list config\n",
    "    omegaconf.nodes.AnyNode,                # Any node in OmegaConf\n",
    "    omegaconf.base.Metadata,                # More OmegaConf metadata\n",
    "    typing.Any,                             # Python typing\n",
    "    dict, list, int,                        # Basic Python types\n",
    "    collections.defaultdict                  # For default dictionaries\n",
    "]):\n",
    "    \n",
    "    # Fit the model\n",
    "    tabular_model.fit(\n",
    "        train=train_df_scaled,  # Training DataFrame (scaled/processed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model.save_model('C:/Users/Sreelakshmi/00_Final_Project_MENG/Approach 1/TabTransformer/tabtransformer_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMB7fTUVene5DzGdeVC1GQQ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (GPU Env)",
   "language": "python",
   "name": "tabular_final_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "042f7e27eef645988c6cb1b789115b3d": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_c18f83f18fae42acb31405b8f6e8d74c",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 13/19 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">3/3</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">42.41it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">v_num: 0.000 train_loss: 0.356      </span>\n                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">valid_loss: 0.610 valid_accuracy:   </span>\n                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.747 train_accuracy: 0.875         </span>\n</pre>\n",
         "text/plain": "Epoch 13/19 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m3/3\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m42.41it/s\u001b[0m \u001b[37mv_num: 0.000 train_loss: 0.356      \u001b[0m\n                                                                               \u001b[37mvalid_loss: 0.610 valid_accuracy:   \u001b[0m\n                                                                               \u001b[37m0.747 train_accuracy: 0.875         \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "a6905af35b9444c8bde9a01e6c18ea2b": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_bff87e2c611e49a6b6613dbe184b0160",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 13/19 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">3/3</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:00 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">24.22it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">v_num: 0.000 train_loss: 0.356      </span>\n                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">valid_loss: 0.610 valid_accuracy:   </span>\n                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.747 train_accuracy: 0.875         </span>\n</pre>\n",
         "text/plain": "Epoch 13/19 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m3/3\u001b[0m \u001b[38;5;245m0:00:00 • 0:00:00\u001b[0m \u001b[38;5;249m24.22it/s\u001b[0m \u001b[37mv_num: 0.000 train_loss: 0.356      \u001b[0m\n                                                                               \u001b[37mvalid_loss: 0.610 valid_accuracy:   \u001b[0m\n                                                                               \u001b[37m0.747 train_accuracy: 0.875         \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "bff87e2c611e49a6b6613dbe184b0160": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f83f18fae42acb31405b8f6e8d74c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
